# Nombre de los componentes
agent1.sources = source_logs
agent1.sinks = sink_hdfs
agent1.channels = channel_mem

# FUENTE (Source): Ejecuta tail -F para capturar logs en tiempo real
agent1.sources.source_logs.type = exec
# Añadir la ruta del archivo de logs real (creado en el ngnix-custom.conf)
agent1.sources.source_logs.command = tail -F /var/log/nginx/real_access.log 
agent1.sources.source_logs.shell = /bin/bash -c

# CANAL (Channel): Guarda los eventos en memoria temporalmente
agent1.channels.channel_mem.type = memory
agent1.channels.channel_mem.capacity = 10000
agent1.channels.channel_mem.transactionCapacity = 1000

# SUMIDERO (Sink): Envía los datos a HDFS
agent1.sinks.sink_hdfs.type = hdfs
agent1.sinks.sink_hdfs.hdfs.path = hdfs://hadoop:9000/user/root/logs_web/%Y%m%d
agent1.sinks.sink_hdfs.hdfs.filePrefix = access-
agent1.sinks.sink_hdfs.hdfs.fileType = DataStream
agent1.sinks.sink_hdfs.hdfs.writeFormat = Text
# Rotación de archivos (cada 10 minutos o 100MB)
agent1.sinks.sink_hdfs.hdfs.rollInterval = 600
agent1.sinks.sink_hdfs.hdfs.rollSize = 104857600
agent1.sinks.sink_hdfs.hdfs.rollCount = 0
agent1.sinks.sink_hdfs.hdfs.useLocalTimeStamp = true

# Unión de componentes
agent1.sources.source_logs.channels = channel_mem
agent1.sinks.sink_hdfs.channel = channel_mem
